{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of exercise_4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ec098c441ef94be0874b3d7136e99a18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_01a4c795851b4a528847b76aad2b398d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_32064963fad745769b09c69e8ba2e3fa",
              "IPY_MODEL_cc893a84885b43378c5dcf594432684b",
              "IPY_MODEL_9a4430fd18f94f62b9ab9f23a28da19b"
            ]
          }
        },
        "01a4c795851b4a528847b76aad2b398d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "32064963fad745769b09c69e8ba2e3fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4181692483574dd8b7a941e4be4472ec",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8b45ff8ddd084ce6a8cd812c51c9a4d7"
          }
        },
        "cc893a84885b43378c5dcf594432684b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_86384cf6c29a4fe8ac25a13640b88f80",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1042301,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1042301,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_17eb5d4de97c461c938679ee2a595ee8"
          }
        },
        "9a4430fd18f94f62b9ab9f23a28da19b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_40d588b95cd548f998e16170daf28fb2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 1.12MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dadc8529119e47c29d9d1ce32f24ac64"
          }
        },
        "4181692483574dd8b7a941e4be4472ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8b45ff8ddd084ce6a8cd812c51c9a4d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "86384cf6c29a4fe8ac25a13640b88f80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "17eb5d4de97c461c938679ee2a595ee8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "40d588b95cd548f998e16170daf28fb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dadc8529119e47c29d9d1ce32f24ac64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "40ee98080fb447eaa66f54929e764527": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e05bc5ae30a74d80a39b5b8173879439",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ced47c528ecc4e43a179ea2452ad5ff7",
              "IPY_MODEL_3c7833503bf24a0fbff9bbe678d748fe",
              "IPY_MODEL_76f8967e6f2e466fba3f530cb881d284"
            ]
          }
        },
        "e05bc5ae30a74d80a39b5b8173879439": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ced47c528ecc4e43a179ea2452ad5ff7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_581c4f61f8b84f8381fcfa516966f240",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_214c37b88f284ae68e252b9841f67174"
          }
        },
        "3c7833503bf24a0fbff9bbe678d748fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a1379a8fe7bc455e8d8582550559ab78",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 456318,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 456318,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ec96ac160e704d578c2a331b22541958"
          }
        },
        "76f8967e6f2e466fba3f530cb881d284": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0d24fb7b873e497ebe04679423f3ab33",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 456k/456k [00:00&lt;00:00, 873kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bad3ad9993734783b264f01568e20f48"
          }
        },
        "581c4f61f8b84f8381fcfa516966f240": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "214c37b88f284ae68e252b9841f67174": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a1379a8fe7bc455e8d8582550559ab78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ec96ac160e704d578c2a331b22541958": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0d24fb7b873e497ebe04679423f3ab33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bad3ad9993734783b264f01568e20f48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a0e68f9785f242189e21484a8f134587": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_add07ca7f83a46619ae8f1a7d9f38fad",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8956a00f90524f0db2c06d6cfd0bd9ae",
              "IPY_MODEL_85f8b4a240504f6396d6512636bca2e6",
              "IPY_MODEL_3fb9f2185bed4f9793bc14d199264d75"
            ]
          }
        },
        "add07ca7f83a46619ae8f1a7d9f38fad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8956a00f90524f0db2c06d6cfd0bd9ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4b9e6167aaf149dbb75eeed119ffa6e8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_05a20ce333164f82a3c3898dfc9f9dc0"
          }
        },
        "85f8b4a240504f6396d6512636bca2e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_640b5296ee2b431bbfa3c66148917324",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1355256,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1355256,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_63350e827a934ff4804f37d28cf44c4e"
          }
        },
        "3fb9f2185bed4f9793bc14d199264d75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e1c38b9c9df34a769f69f7710e14f201",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 5.70MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fe80570419104ca4860057898cb9b3d1"
          }
        },
        "4b9e6167aaf149dbb75eeed119ffa6e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "05a20ce333164f82a3c3898dfc9f9dc0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "640b5296ee2b431bbfa3c66148917324": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "63350e827a934ff4804f37d28cf44c4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e1c38b9c9df34a769f69f7710e14f201": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fe80570419104ca4860057898cb9b3d1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e45ace2bcd2140018e10dd9d2fc171d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a9191af7e59a4fc4b6623f337bb49c88",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_bead2ab72817430883a3edc44289ebe2",
              "IPY_MODEL_08e9072d28614afcb0722bf85312f22c",
              "IPY_MODEL_6e4c006ff05f46689ed6cf4848290b96"
            ]
          }
        },
        "a9191af7e59a4fc4b6623f337bb49c88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bead2ab72817430883a3edc44289ebe2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ab9aaad6f36640649f5b233420a9c47a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cadb2d2d788444c2896e803a6a8fc2e2"
          }
        },
        "08e9072d28614afcb0722bf85312f22c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2b40b25cf03b496180a6b1fc94a08676",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 665,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 665,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d3bebe08c1a84b798677507d7078cc22"
          }
        },
        "6e4c006ff05f46689ed6cf4848290b96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_984fb0d7b88b4867930bfced6ae2022b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 665/665 [00:00&lt;00:00, 14.9kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d3a4ded2a6284341b6e3c4b21ca1d4dc"
          }
        },
        "ab9aaad6f36640649f5b233420a9c47a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cadb2d2d788444c2896e803a6a8fc2e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2b40b25cf03b496180a6b1fc94a08676": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d3bebe08c1a84b798677507d7078cc22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "984fb0d7b88b4867930bfced6ae2022b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d3a4ded2a6284341b6e3c4b21ca1d4dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ce5fdfc2be3449b7aa0daf329814af21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_854263b72ba142e19269589573608748",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9fc63361eee746ea9121024f18cbc3a7",
              "IPY_MODEL_510493072efd4a548febffcf741ec747",
              "IPY_MODEL_647cb483a33e4394b388b07d52ad17d3"
            ]
          }
        },
        "854263b72ba142e19269589573608748": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9fc63361eee746ea9121024f18cbc3a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bd44662c9abd4acb8f6293756c496637",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ef231a5da93f42b6b7d891e0c268fddc"
          }
        },
        "510493072efd4a548febffcf741ec747": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3ce9227da501480fbb3abdfa0387ca7d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 497933648,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 497933648,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_97b3f59779134cd6b28df88a9e787e02"
          }
        },
        "647cb483a33e4394b388b07d52ad17d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d6205cbfe5d54e4d828977671e7a3661",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 498M/498M [00:27&lt;00:00, 8.30MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3e27cf037c3a4123a69a4c79c1bf7575"
          }
        },
        "bd44662c9abd4acb8f6293756c496637": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ef231a5da93f42b6b7d891e0c268fddc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3ce9227da501480fbb3abdfa0387ca7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "97b3f59779134cd6b28df88a9e787e02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d6205cbfe5d54e4d828977671e7a3661": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3e27cf037c3a4123a69a4c79c1bf7575": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfTh4bUzAmSX"
      },
      "source": [
        "<h1 style=\"padding-top: 25px;padding-bottom: 25px;text-align: left; padding-left: 10px; background-color: #DDDDDD; \n",
        "    color: black;\"> <img style=\"float: left; padding-right: 10px;\" src=\"https://storage.googleapis.com/dlops-content/public/univailogo.jpeg\" height=\"50px\"> <a href='https://welcome.univ.ai/AcceleratedMasters/ai5-c1/' target='_blank'><strong><font color=\"#324bd9\">AI-5: Productionizing AI (MLOps)</font></strong></a></h1>\n",
        "\n",
        "# **<font color=\"#324bd9\">Exercise 4 - Language Models</font>**\n",
        "\n",
        "**Univ.AI**<br/>\n",
        "**August 2021**<br/>\n",
        "**Instructors:**<br/>\n",
        "Pavlos Protopapas, Shivas Jayaram\n",
        "\n",
        "<hr style=\"height:2pt\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgY9xWhgGdt8"
      },
      "source": [
        "## **<font color=\"#324bd9\">Setup Notebook</font>**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-HGo-xOGr2t"
      },
      "source": [
        "**Copy & setup Colab**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qfXH3wYGtSa"
      },
      "source": [
        "1) Select \"File\" menu and pick \"Save a copy in Drive\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TljsNDvO8mex"
      },
      "source": [
        "**Installs**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpB5zrQm8m8y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ca40426-56a5-4ca3-f397-49ba438fabeb"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.10.0-py3-none-any.whl (2.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.8 MB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.4)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 30.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting huggingface-hub>=0.0.12\n",
            "  Downloading huggingface_hub-0.0.16-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 4.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 31.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 33.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Installing collected packages: tokenizers, sacremoses, pyyaml, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.0.16 pyyaml-5.4.1 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsHQIdyQHAkV"
      },
      "source": [
        "**Imports**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dB7OG0AQAlha"
      },
      "source": [
        "import os\n",
        "import requests\n",
        "import zipfile\n",
        "import tarfile\n",
        "import shutil\n",
        "import math\n",
        "import json\n",
        "import time\n",
        "import sys\n",
        "import string\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from glob import glob\n",
        "import collections\n",
        "import unicodedata\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "%matplotlib inline\n",
        "\n",
        "# Tensorflow\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.python.keras import backend as K\n",
        "from tensorflow.python.keras.utils.layer_utils import count_params\n",
        "\n",
        "# sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# NLTK\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "\n",
        "# Transformers\n",
        "from transformers import GPT2Tokenizer, TFGPT2LMHeadModel, GPT2Config"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTFTOvfCzl4P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb5c2908-c72c-4d95-8119-036f08b05887"
      },
      "source": [
        "# download nltk's punkt sentence tokenizer\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "994rWwzOz3k7"
      },
      "source": [
        "**Verify Setup**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQv78tzHz3w6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b701579-51de-4910-a9f4-68ff25ae63fa"
      },
      "source": [
        "# Enable/Disable Eager Execution\n",
        "# Reference: https://www.tensorflow.org/guide/eager\n",
        "# TensorFlow's eager execution is an imperative programming environment that evaluates operations immediately, \n",
        "# without building graphs\n",
        "\n",
        "#tf.compat.v1.disable_eager_execution()\n",
        "#tf.compat.v1.enable_eager_execution()\n",
        "\n",
        "print(\"tensorflow version\", tf.__version__)\n",
        "print(\"keras version\", tf.keras.__version__)\n",
        "print(\"Eager Execution Enabled:\", tf.executing_eagerly())\n",
        "\n",
        "# Get the number of replicas \n",
        "strategy = tf.distribute.MirroredStrategy()\n",
        "print(\"Number of replicas:\", strategy.num_replicas_in_sync)\n",
        "\n",
        "devices = tf.config.experimental.get_visible_devices()\n",
        "print(\"Devices:\", devices)\n",
        "print(tf.config.experimental.list_logical_devices('GPU'))\n",
        "\n",
        "print(\"GPU Available: \", tf.config.list_physical_devices('GPU'))\n",
        "print(\"All Physical Devices\", tf.config.list_physical_devices())\n",
        "\n",
        "# Better performance with the tf.data API\n",
        "# Reference: https://www.tensorflow.org/guide/data_performance\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensorflow version 2.6.0\n",
            "keras version 2.6.0\n",
            "Eager Execution Enabled: True\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "Number of replicas: 1\n",
            "Devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "[LogicalDevice(name='/device:GPU:0', device_type='GPU')]\n",
            "GPU Available:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "All Physical Devices [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4ku4_MtNBRw"
      },
      "source": [
        "**Utils**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hne8Ftz_NBdS"
      },
      "source": [
        "def download_file(packet_url, base_path=\"\", extract=False, headers=None):\n",
        "  if base_path != \"\":\n",
        "    if not os.path.exists(base_path):\n",
        "      os.mkdir(base_path)\n",
        "  packet_file = os.path.basename(packet_url)\n",
        "  with requests.get(packet_url, stream=True, headers=headers) as r:\n",
        "      r.raise_for_status()\n",
        "      with open(os.path.join(base_path,packet_file), 'wb') as f:\n",
        "          for chunk in r.iter_content(chunk_size=8192):\n",
        "              f.write(chunk)\n",
        "  \n",
        "  if extract:\n",
        "    if packet_file.endswith(\".zip\"):\n",
        "      with zipfile.ZipFile(os.path.join(base_path,packet_file)) as zfile:\n",
        "        zfile.extractall(base_path)\n",
        "    else:\n",
        "      packet_name = packet_file.split('.')[0]\n",
        "      with tarfile.open(os.path.join(base_path,packet_file)) as tfile:\n",
        "        tfile.extractall(base_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQN49faACzOK"
      },
      "source": [
        "## **Mini BERT**\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i160Yl_4C5td"
      },
      "source": [
        "In this exercise, you are going to be working with some text related to machine & deep learning. The data is a very small set of defintions pulled from wikipedia. The primary goal will be to understand BERT(Bidirectional Encoder Representations from Transformers) architecture.\n",
        "\n",
        "**The Task:** Build a masked language model using a simplified version of the BERT. \n",
        "\n",
        "\n",
        "**Language Model**: \n",
        "\n",
        "A model that understands language and how words appear in context to one another. The model is trained using unsupervised approaches such as next word prediction in a sentence or next sentence prediction.\n",
        "\n",
        "\n",
        "**Review BERT**:\n",
        "\n",
        "* Masked Language Model\n",
        "* Made up of only the Encoder with stacked transformer blocks\n",
        "* Bidirectional language\n",
        "* Good for fill in the blanks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34pjt7SmDIJ6"
      },
      "source": [
        "### **Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wX05NQWADLiL"
      },
      "source": [
        "#### **Download Dataset**\n",
        "\n",
        "Download the datasets to colab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpoRSKBUDO6n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adf58412-753d-4821-eeb5-e11749c53edf"
      },
      "source": [
        "start_time = time.time()\n",
        "download_file(\"https://github.com/dlops-io/datasets/releases/download/v1.0/deep_learning_terms.txt\", base_path=\"datasets\", extract=False)\n",
        "execution_time = (time.time() - start_time)/60.0\n",
        "print(\"Download execution time (mins)\",execution_time)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download execution time (mins) 0.007071165243784586\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q04WptRBKmKQ"
      },
      "source": [
        "#### **Load Data**\n",
        "\n",
        "* Read-in data as lists."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlLG9QHNKmnn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "231641eb-6508-45ef-d337-f81d61685c70"
      },
      "source": [
        "data_text_file = os.path.join(\"datasets\",\"deep_learning_terms.txt\")\n",
        "data_text = []\n",
        "with open(data_text_file) as file:\n",
        "  for line in file:\n",
        "    data_text.append(line)\n",
        "\n",
        "print(\"data_text len:\", len(data_text))\n",
        "\n",
        "# Get sentences\n",
        "sentences = []\n",
        "for text in data_text:\n",
        "  sentences.extend(sent_tokenize(text))\n",
        "\n",
        "# Add a few DEMO sentence\n",
        "sentences.append(\"pavlos taught positional encoding to shivas\")\n",
        "print(\"sentences len:\", len(sentences))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data_text len: 20\n",
            "sentences len: 183\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YjzpJoVyKrHo"
      },
      "source": [
        "#### **View Text**\n",
        "\n",
        "Let's take a look at the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pst-YbVZKrmM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "37653539-5542-4b87-82ad-6a415a8d35d7"
      },
      "source": [
        "display(sentences[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "['Deep learning also known as deep structured learning is part of a broader family of machine learning methods based on artificial neural networks with representation learning.',\n",
              " 'Learning can be supervised, semi-supervised or unsupervised.',\n",
              " 'Deep-learning architectures such as deep neural networks, deep belief networks, recurrent neural networks and convolutional neural networks have been applied to fields including computer vision, machine vision, speech recognition, natural language processing, audio recognition, social network filtering, machine translation, bioinformatics, drug design, medical image analysis, material inspection and board game programs, where they have produced results comparable to and in some cases surpassing human expert performance.',\n",
              " 'Artificial neural networks (ANNs) were inspired by information processing and distributed communication nodes in biological systems.',\n",
              " 'ANNs have various differences from biological brains.',\n",
              " 'Specifically, neural networks tend to be static and symbolic, while the biological brain of most living organisms is dynamic (plastic) and analogue.',\n",
              " 'The adjective deep in deep learning refers to the use of multiple layers in the network.',\n",
              " 'Early work showed that a linear perceptron cannot be a universal classifier, and then that a network with a nonpolynomial activation function with one hidden layer of unbounded width can on the other hand so be.',\n",
              " 'Deep learning is a modern variation which is concerned with an unbounded number of layers of bounded size, which permits practical application and optimized implementation, while retaining theoretical universality under mild conditions.',\n",
              " 'In deep learning the layers are also permitted to be heterogeneous and to deviate widely from biologically informed connectionist models, for the sake of efficiency, trainability and understandability, whence the structured part.']"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73voKp55KxTH"
      },
      "source": [
        "### **Build Data Pipelines**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ofnzqZYK0SM"
      },
      "source": [
        "#### **Text Vectorization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fN5oM5eRK2kW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63acc4b9-aa17-4964-8b46-63428fdf44ce"
      },
      "source": [
        "MASK_TOKEN = \"[mask]\"\n",
        "max_len = max([len(x.split()) for x in sentences])\n",
        "print(\"max_len\",max_len)\n",
        "\n",
        "def standardize_text(input_text):\n",
        "  # Convert to lowercase\n",
        "  output_text = tf.strings.lower(input_text) \n",
        "  return tf.strings.regex_replace(\n",
        "        output_text, \"[%s]\" % re.escape(\"!#$%&'()*+,-./:;<=>?@\\^_`{|}~\"), \"\"\n",
        "    )\n",
        "\n",
        "text_data = tf.data.Dataset.from_tensor_slices(sentences)\n",
        "\n",
        "# Initialize Text Vectorizer\n",
        "text_vectorizer = TextVectorization(\n",
        "    standardize=standardize_text,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=max_len\n",
        ")\n",
        "\n",
        "# Generate Text Vector\n",
        "text_vectorizer.adapt(sentences)\n",
        "\n",
        "# Get Vocabulary\n",
        "vocabulary = text_vectorizer.get_vocabulary()\n",
        "vocabulary_size = len(vocabulary)\n",
        "# Add the mask token\n",
        "vocabulary = vocabulary[2 : vocabulary_size - 1] + [MASK_TOKEN]\n",
        "text_vectorizer.set_vocabulary(vocabulary)\n",
        "vocabulary = text_vectorizer.get_vocabulary()\n",
        "vocabulary_size = len(vocabulary)\n",
        "print(\"Vocabulary Size:\",vocabulary_size)\n",
        "print(vocabulary[-1])\n",
        "\n",
        "# Generate word index\n",
        "word_index = dict(zip(vocabulary, range(vocabulary_size)))\n",
        "index_word = dict(zip(range(vocabulary_size), vocabulary))\n",
        "\n",
        "print(\"vocabulary:\",len(vocabulary),vocabulary)\n",
        "print(\"word_index:\",word_index)\n",
        "\n",
        "# Get mask token id for masked language model\n",
        "mask_token_id = word_index[MASK_TOKEN]\n",
        "print(\"Mask token Id:\", mask_token_id)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "max_len 66\n",
            "Vocabulary Size: 1130\n",
            "[mask]\n",
            "vocabulary: 1130 ['', '[UNK]', 'the', 'of', 'a', 'to', 'and', 'is', 'in', 'learning', 'that', 'as', 'or', 'data', 'can', 'with', 'neural', 'networks', 'be', 'language', 'such', 'an', 'are', 'machine', 'image', 'from', 'for', 'network', 'this', 'model', 'on', 'layers', 'it', 'artificial', 'training', 'deep', 'by', 'also', 'recognition', 'layer', 'computer', 'used', 'natural', 'input', 'have', 'which', 'translation', 'not', 'neurons', 'where', 'process', 'human', 'between', 'words', 'vision', 'supervised', 'speech', 'processing', 'field', 'feature', 'systems', 'recurrent', 'output', 'nlg', 'more', 'its', 'intelligence', 'each', 'understanding', 'tasks', 'signal', 'representation', 'other', 'one', 'labeled', 'known', 'into', 'images', 'different', 'biological', 'algorithms', 'when', 'visual', 'unsupervised', 'they', 'than', 'segmentation', 'produce', 'models', 'lstm', 'information', 'but', 'use', 'through', 'system', 'set', 'sequences', 'semisupervised', 'rnns', 'only', 'multiple', 'methods', 'impulse', 'hidden', 'function', 'features', 'example', 'connected', 'called', 'based', 'algorithm', 'while', 'video', 'units', 'transformer', 'trained', 'time', 'text', 'similar', 'problem', 'probability', 'often', 'memory', 'many', 'include', 'has', 'examples', 'detection', 'connections', 'computers', 'classification', 'applications', 'allows', '3d', 'whereas', 'using', 'unlabeled', 'typically', 'transformers', 'then', 'them', 'supervision', 'study', 'statistical', 'specific', 'sequence', 'representations', 'phrases', 'perform', 'patterns', 'part', 'over', 'nlu', 'needs', 'naturallanguage', 'medical', 'may', 'make', 'long', 'like', 'inputs', 'graph', 'eg', 'documents', 'dnn', 'digital', 'composition', 'complex', 'cnns', 'class', 'applied', 'application', 'another', 'analysis', 'world', 'word', 'without', 'within', 'were', 'was', 'visible', 'usually', 'unlike', 'ul', 'threshold', 'there', 'theory', 'their', 'term', 'temporal', 'take', 'symbolic', 'structured', 'some', 'software', 'shortterm', 'series', 'same', 'referred', 'produces', 'processes', 'predictions', 'practical', 'pixels', 'order', 'object', 'nodes', 'nlp', 'neuron', 'needed', 'multilayer', 'most', 'modeling', 'mathematical', 'makes', 'machines', 'length', 'large', 'languages', 'label', 'inspired', 'infinite', 'if', 'humans', 'how', 'handwriting', 'given', 'generative', 'generate', 'general', 'gated', 'gate', 'forms', 'finite', 'feedforward', 'feedback', 'etc', 'entire', 'easier', 'dynamic', 'do', 'directed', 'decisions', 'dbn', 'convolutional', 'connection', 'concerned', 'compared', 'characteristics', 'certain', 'cell', 'brains', 'brain', 'both', 'been', 'at', 'anns', 'amount', 'all', 'ai', 'after', 'advantage', 'will', 'whole', 'well', 'weights', 'weight', 'viewed', 'various', 'variety', 'value', 'user', 'unsegmented', 'unseen', 'unrolled', 'unigram', 'under', 'unbounded', 'typical', 'two', 'turn', 'traditional', 'times', 'these', 'therefore', 'theoretical', 'tend', 'techniques', 'task', 'tagged', 'synapses', 'subfield', 'structure', 'storage', 'statistics', 'states', 'state', 'sound', 'solving', 'so', 'smaller', 'small', 'situations', 'single', 'since', 'shallow', 'sets', 'sequential', 'sentence', 'segments', 'seen', 'seeks', 'see', 'scientific', 'scene', 'rnn', 'results', 'result', 'restricted', 'respect', 'requires', 'require', 'reports', 'replaced', 'relatively', 'relative', 'related', 'regularization', 'region', 'recognize', 'receptive', 'real', 'pretrained', 'precisely', 'possible', 'performance', 'perceptrons', 'perceptron', 'pattern', 'particular', 'parallelization', 'pair', 'out', 'objects', 'numerical', 'number', 'nonlinear', 'next', 'n', 'much', 'mt', 'ml', 'means', 'mean', 'making', 'major', 'lstms', 'lowest', 'lower', 'linguistics', 'learns', 'learned', 'learn', 'leading', 'kernels', 'invariant', 'introduced', 'internal', 'interactive', 'instance', 'including', 'ideas', 'however', 'generation', 'generally', 'functions', 'fully', 'form', 'filters', 'filtering', 'fields', 'extraction', 'extract', 'expressed', 'exhibit', 'estimation', 'engineering', 'edges', 'during', 'domains', 'dog', 'dnns', 'discover', 'discipline', 'differences', 'dictionary', 'device', 'determining', 'define', 'deal', 'datasets', 'custom', 'cover', 'corpus', 'convolution', 'contours', 'context', 'content', 'consisting', 'connectivity', 'computed', 'computational', 'composed', 'components', 'complexity', 'common', 'classes', 'building', 'build', 'broad', 'belief', 'behavior', 'before', 'automatically', 'automate', 'autoencoders', 'audio', 'attempts', 'architectures', 'architecture', 'approach', 'applicable', 'any', 'ann', 'animal', 'analyzing', 'analyze', 'allow', 'acquisition', '“recurrent', 'yielded', 'writing', 'wreck', 'work', 'wikipedia', 'width', 'widely', 'wide', 'whether', 'whence', 'wellsuited', 'web', 'weather', 'weak', 'ways', 'way', 'wants', 'vs', 'views', 'videos', 'versions', 'vector', 'varying', 'variation', 'variables', 'variable', 'vanishing', 'values', 'vaguely', 'useful', 'usable', 'untagged', 'unsupervisedin', 'unknown', 'universality', 'universal', 'unit', 'unfeasible', 'undirected', 'understandability', 'understand', 'typology', 'types', 'type', 'trimming', 'tries', 'traversing', 'travel', 'transpilers', 'transmit', 'translators', 'translations', 'translate', 'transforms', 'transformations', 'transformation', 'transcribe', 'trainability', 'traffic', 'tracking', 'towards', 'thus', 'three', 'thought', 'those', 'things', 'theories', 'themselves', 'texture', 'textual', 'texttospeech', 'textbooks', 'terms', 'technology', 'technological', 'technique', 'taught', 'target', 'takes', 'tagging', 'symmetrical', 'surpassing', 'supervisory', 'summarization', 'sum', 'successfully', 'substitutions', 'substitution', 'subset', 'subnetworks', 'subnetwork', 'subdomains', 'strong', 'strictly', 'strength', 'stored', 'stimuli', 'step', 'static', 'starting', 'standardised', 'standard', 'stack', 'spectrum', 'specifically', 'special', 'sparsity', 'sparse', 'space', 'sounds', 'sometimes', 'something', 'solution', 'social', 'socalled', 'sl', 'skilled', 'size', 'simply', 'simplify', 'simpler', 'simple', 'similarly', 'significantly', 'signals', 'siann', 'showed', 'should', 'short', 'shivas', 'shift', 'sharedweight', 'share', 'servoing', 'serves', 'sent', 'sensor', 'sense', 'selforganization', 'selfconsistent', 'select', 'segment', 'score', 'scope', 'science', 'scenario', 'scanning', 'scanner', 'scan', 'scale', 'say', 'sample', 'sake', 'review', 'revealed', 'return', 'retrieval', 'retina', 'retaining', 'resulting', 'restoration', 'respond', 'resolve', 'resembles', 'research', 'replacing', 'replaces', 'render', 'remembers', 'relying', 'relationships', 'reinforcement', 'regulate', 'regularized', 'regions', 'refers', 'refer', 'reduced', 'reconstructions', 'reconstruction', 'reconstruct', 'recommender', 'receives', 'reasonable', 'realworld', 'readily', 'read', 'rbms', 'rbm', 'raw', 'rarely', 'rapidlygrowing', 'rapidly', 'randomly', 'quality', 'put', 'psychological', 'psycholinguists', 'provides', 'proved', 'protein', 'proposed', 'property', 'pronunciation', 'prone', 'programs', 'programming', 'programmed', 'program', 'profession', 'production', 'produced', 'processed', 'proceeds', 'procedure', 'problems[2]', 'problems', 'probabilities', 'probabilistically', 'probabilistic', 'prior', 'primitives', 'primarily', 'previous', 'preprocessing', 'prefer', 'predictive', 'predelections', 'potentially', 'potential', 'possibly', 'positional', 'pose', 'portion', 'polynomials', 'points', 'plastic', 'pixel', 'physics', 'physical', 'perspective', 'permitted', 'permits', 'performs', 'performing', 'perceives', 'pavlos', 'partofspeech', 'partitioning', 'particularly', 'partially', 'parsing', 'pairs', 'overlap', 'overfitting', 'organize', 'organizations', 'organization', 'organisms', 'optimized', 'optimize', 'optimization', 'optimal', 'optical', 'opposite', 'older', 'oil', 'observed', 'numerous', 'nuances', 'normalized', 'nonpolynomial', 'no', 'nns', 'nice', 'ngram', 'new', 'neuronal', 'network”', 'need', 'name', 'multivariate', 'multidimensional', 'motivated', 'motion', 'modern', 'modeled', 'mobile', 'mining', 'minimized', 'mind', 'mimicry', 'mimic', 'mild', 'might', 'mechanical', 'measured', 'meaningful', 'meaning', 'maximize', 'matrix', 'mathematically', 'material', 'matched', 'markov', 'marching', 'maps', 'mapping', 'manual', 'manipulation', 'machineaided', 'm', 'loss', 'loosely', 'loops', 'location', 'locate', 'living', 'little', 'linguistic', 'lines', 'linear', 'limiting', 'likelihood', 'levels', 'level', 'less', 'legal', 'led', 'leads', 'layered', 'layerbylayer', 'latter', 'latent', 'last', 'larger', 'lags', 'labels', 'labelled', 'labeling', 'knowledge', 'isolation', 'involves', 'involve', 'investigates', 'invariance', 'intrusion', 'intervention', 'intervals', 'interpolation', 'intermediate', 'interfaces', 'interest', 'interdisciplinary', 'interactions', 'intensity', 'intelligent', 'integrated', 'instances', 'inspection', 'insights', 'insensitivity', 'inputoutput', 'informed', 'infers', 'inferred', 'infeasible', 'inexpensive', 'inductive', 'individual', 'indiscriminately', 'indexing', 'independent', 'independence', 'increasing', 'increases', 'incorporates', 'improving', 'improvement', 'improve', 'important', 'implementation', 'imaging', 'imagery', 'idss', 'idioms', 'idea', 'humanreadable', 'huge', 'hope', 'highlevel', 'highdimensional', 'hierarchical', 'heterogeneous', 'hence', 'help', 'handling', 'handle', 'handengineered', 'hand', 'guidance', 'great', 'graphical', 'gradient', 'gpt', 'government', 'good', 'goals', 'goal', 'go', 'gets', 'geometry', 'generated', 'generalize', 'generalization', 'gates', 'gap', 'game', 'gain', 'further', 'functioning', 'fullyconnectedness', 'frequently', 'formulaic', 'former', 'formal', 'forget', 'forced', 'follows', 'focusing', 'focuses', 'fnn', 'flow', 'fish', 'first', 'finetuned', 'financial', 'fewer', 'fast', 'family', 'falls', 'factorization', 'fact', 'facilitates', 'extreme', 'extracted', 'extra', 'expression', 'express', 'exponentially', 'exploratory', 'explicitly', 'explicit', 'expert', 'experiment', 'experience', 'exhibits', 'examination', 'evidence', 'every', 'events', 'event', 'even', 'estimating', 'especially', 'error', 'erroneous', 'equivalent', 'environment', 'english', 'energybased', 'end', 'encountered', 'encoding', 'encoder', 'enabled', 'enable', 'emulate', 'emotionality', 'embossed', 'email', 'elicit', 'either', 'efficiency', 'effective', 'edge', 'early', 'duration', 'due', 'drug', 'domain', 'does', 'divergence', 'distribution', 'distributed', 'distinguish', 'distinction', 'displayed', 'display', 'disentangling', 'disambiguate', 'direct', 'difficult', 'deviate', 'development', 'developed', 'develop', 'determine', 'detectors', 'desired', 'designed', 'design', 'descriptions', 'described', 'describe', 'derived', 'depends', 'densities', 'demonstrated', 'delivers', 'delays', 'deeplearning', 'decreases', 'decompilers', 'deals', 'dbns', 'cyclic', 'customization', 'curves', 'current', 'cubes', 'crosses', 'create', 'crawl', 'counterparts', 'cost', 'cortical', 'cortex', 'correctly', 'convnet', 'conversations', 'conversation', 'conventional', 'convenient', 'controlled', 'control', 'contrastive', 'contrast', 'contextual', 'contents', 'contained', 'construction', 'constructed', 'constitute', 'consist', 'considered', 'considerations', 'considerably', 'considerable', 'consciousness', 'connectionist', 'connectedness', 'conjunction', 'confused', 'conditions', 'concept', 'computing', 'computeraided', 'computationally', 'compositional', 'component', 'comparable', 'compact', 'communication', 'commonly', 'combines', 'color', 'colloquially', 'collectively', 'collection', 'cognitive', 'code', 'cnn', 'clustering', 'closest', 'closely', 'classifying', 'classifier', 'chosen', 'choose', 'choice', 'chatbot', 'characteristic', 'character', 'change', 'chance', 'challenging', 'challenges', 'categorize', 'categories', 'cases', 'car', 'captures', 'capable', 'cannot', 'cameras', 'calculate', 'business', 'broader', 'breeds', 'breed', 'braincomputer', 'bounded', 'boundaries', 'boltzmann', 'board', 'blurbs', 'biologically', 'bioinformatics', 'bidirectional', 'biases', 'bias', 'better', 'bert', 'being', 'behind', 'beginning', 'become', 'because', 'beach', 'basic', 'bag', 'automated', 'assumption', 'associated', 'associate', 'assigns', 'assigning', 'assemble', 'arbitrary', 'approximate', 'appropriate', 'apply', 'anomaly', 'anomalies', 'animals', 'andor', 'analyzes', 'analytics', 'analogue', 'amounts', 'american', 'ambiguous', 'ambiguity', 'ambiguities', 'always', 'alternatively', 'alternative', 'along', 'alone', 'allowable', 'algorithmically', 'aid', 'agi', 'aggregated', 'aggregate', 'agents', 'agent', 'adjusts', 'adjective', 'adjacent', 'additional', 'acyclic', 'activation', 'actions', 'action', 'act', 'across', 'acronym', 'acquiring', 'acoustic', 'achieving', 'accurately', 'accuracy', 'above', 'about', 'abi', 'abbreviation', '2017', '[mask]']\n",
            "word_index: {'': 0, '[UNK]': 1, 'the': 2, 'of': 3, 'a': 4, 'to': 5, 'and': 6, 'is': 7, 'in': 8, 'learning': 9, 'that': 10, 'as': 11, 'or': 12, 'data': 13, 'can': 14, 'with': 15, 'neural': 16, 'networks': 17, 'be': 18, 'language': 19, 'such': 20, 'an': 21, 'are': 22, 'machine': 23, 'image': 24, 'from': 25, 'for': 26, 'network': 27, 'this': 28, 'model': 29, 'on': 30, 'layers': 31, 'it': 32, 'artificial': 33, 'training': 34, 'deep': 35, 'by': 36, 'also': 37, 'recognition': 38, 'layer': 39, 'computer': 40, 'used': 41, 'natural': 42, 'input': 43, 'have': 44, 'which': 45, 'translation': 46, 'not': 47, 'neurons': 48, 'where': 49, 'process': 50, 'human': 51, 'between': 52, 'words': 53, 'vision': 54, 'supervised': 55, 'speech': 56, 'processing': 57, 'field': 58, 'feature': 59, 'systems': 60, 'recurrent': 61, 'output': 62, 'nlg': 63, 'more': 64, 'its': 65, 'intelligence': 66, 'each': 67, 'understanding': 68, 'tasks': 69, 'signal': 70, 'representation': 71, 'other': 72, 'one': 73, 'labeled': 74, 'known': 75, 'into': 76, 'images': 77, 'different': 78, 'biological': 79, 'algorithms': 80, 'when': 81, 'visual': 82, 'unsupervised': 83, 'they': 84, 'than': 85, 'segmentation': 86, 'produce': 87, 'models': 88, 'lstm': 89, 'information': 90, 'but': 91, 'use': 92, 'through': 93, 'system': 94, 'set': 95, 'sequences': 96, 'semisupervised': 97, 'rnns': 98, 'only': 99, 'multiple': 100, 'methods': 101, 'impulse': 102, 'hidden': 103, 'function': 104, 'features': 105, 'example': 106, 'connected': 107, 'called': 108, 'based': 109, 'algorithm': 110, 'while': 111, 'video': 112, 'units': 113, 'transformer': 114, 'trained': 115, 'time': 116, 'text': 117, 'similar': 118, 'problem': 119, 'probability': 120, 'often': 121, 'memory': 122, 'many': 123, 'include': 124, 'has': 125, 'examples': 126, 'detection': 127, 'connections': 128, 'computers': 129, 'classification': 130, 'applications': 131, 'allows': 132, '3d': 133, 'whereas': 134, 'using': 135, 'unlabeled': 136, 'typically': 137, 'transformers': 138, 'then': 139, 'them': 140, 'supervision': 141, 'study': 142, 'statistical': 143, 'specific': 144, 'sequence': 145, 'representations': 146, 'phrases': 147, 'perform': 148, 'patterns': 149, 'part': 150, 'over': 151, 'nlu': 152, 'needs': 153, 'naturallanguage': 154, 'medical': 155, 'may': 156, 'make': 157, 'long': 158, 'like': 159, 'inputs': 160, 'graph': 161, 'eg': 162, 'documents': 163, 'dnn': 164, 'digital': 165, 'composition': 166, 'complex': 167, 'cnns': 168, 'class': 169, 'applied': 170, 'application': 171, 'another': 172, 'analysis': 173, 'world': 174, 'word': 175, 'without': 176, 'within': 177, 'were': 178, 'was': 179, 'visible': 180, 'usually': 181, 'unlike': 182, 'ul': 183, 'threshold': 184, 'there': 185, 'theory': 186, 'their': 187, 'term': 188, 'temporal': 189, 'take': 190, 'symbolic': 191, 'structured': 192, 'some': 193, 'software': 194, 'shortterm': 195, 'series': 196, 'same': 197, 'referred': 198, 'produces': 199, 'processes': 200, 'predictions': 201, 'practical': 202, 'pixels': 203, 'order': 204, 'object': 205, 'nodes': 206, 'nlp': 207, 'neuron': 208, 'needed': 209, 'multilayer': 210, 'most': 211, 'modeling': 212, 'mathematical': 213, 'makes': 214, 'machines': 215, 'length': 216, 'large': 217, 'languages': 218, 'label': 219, 'inspired': 220, 'infinite': 221, 'if': 222, 'humans': 223, 'how': 224, 'handwriting': 225, 'given': 226, 'generative': 227, 'generate': 228, 'general': 229, 'gated': 230, 'gate': 231, 'forms': 232, 'finite': 233, 'feedforward': 234, 'feedback': 235, 'etc': 236, 'entire': 237, 'easier': 238, 'dynamic': 239, 'do': 240, 'directed': 241, 'decisions': 242, 'dbn': 243, 'convolutional': 244, 'connection': 245, 'concerned': 246, 'compared': 247, 'characteristics': 248, 'certain': 249, 'cell': 250, 'brains': 251, 'brain': 252, 'both': 253, 'been': 254, 'at': 255, 'anns': 256, 'amount': 257, 'all': 258, 'ai': 259, 'after': 260, 'advantage': 261, 'will': 262, 'whole': 263, 'well': 264, 'weights': 265, 'weight': 266, 'viewed': 267, 'various': 268, 'variety': 269, 'value': 270, 'user': 271, 'unsegmented': 272, 'unseen': 273, 'unrolled': 274, 'unigram': 275, 'under': 276, 'unbounded': 277, 'typical': 278, 'two': 279, 'turn': 280, 'traditional': 281, 'times': 282, 'these': 283, 'therefore': 284, 'theoretical': 285, 'tend': 286, 'techniques': 287, 'task': 288, 'tagged': 289, 'synapses': 290, 'subfield': 291, 'structure': 292, 'storage': 293, 'statistics': 294, 'states': 295, 'state': 296, 'sound': 297, 'solving': 298, 'so': 299, 'smaller': 300, 'small': 301, 'situations': 302, 'single': 303, 'since': 304, 'shallow': 305, 'sets': 306, 'sequential': 307, 'sentence': 308, 'segments': 309, 'seen': 310, 'seeks': 311, 'see': 312, 'scientific': 313, 'scene': 314, 'rnn': 315, 'results': 316, 'result': 317, 'restricted': 318, 'respect': 319, 'requires': 320, 'require': 321, 'reports': 322, 'replaced': 323, 'relatively': 324, 'relative': 325, 'related': 326, 'regularization': 327, 'region': 328, 'recognize': 329, 'receptive': 330, 'real': 331, 'pretrained': 332, 'precisely': 333, 'possible': 334, 'performance': 335, 'perceptrons': 336, 'perceptron': 337, 'pattern': 338, 'particular': 339, 'parallelization': 340, 'pair': 341, 'out': 342, 'objects': 343, 'numerical': 344, 'number': 345, 'nonlinear': 346, 'next': 347, 'n': 348, 'much': 349, 'mt': 350, 'ml': 351, 'means': 352, 'mean': 353, 'making': 354, 'major': 355, 'lstms': 356, 'lowest': 357, 'lower': 358, 'linguistics': 359, 'learns': 360, 'learned': 361, 'learn': 362, 'leading': 363, 'kernels': 364, 'invariant': 365, 'introduced': 366, 'internal': 367, 'interactive': 368, 'instance': 369, 'including': 370, 'ideas': 371, 'however': 372, 'generation': 373, 'generally': 374, 'functions': 375, 'fully': 376, 'form': 377, 'filters': 378, 'filtering': 379, 'fields': 380, 'extraction': 381, 'extract': 382, 'expressed': 383, 'exhibit': 384, 'estimation': 385, 'engineering': 386, 'edges': 387, 'during': 388, 'domains': 389, 'dog': 390, 'dnns': 391, 'discover': 392, 'discipline': 393, 'differences': 394, 'dictionary': 395, 'device': 396, 'determining': 397, 'define': 398, 'deal': 399, 'datasets': 400, 'custom': 401, 'cover': 402, 'corpus': 403, 'convolution': 404, 'contours': 405, 'context': 406, 'content': 407, 'consisting': 408, 'connectivity': 409, 'computed': 410, 'computational': 411, 'composed': 412, 'components': 413, 'complexity': 414, 'common': 415, 'classes': 416, 'building': 417, 'build': 418, 'broad': 419, 'belief': 420, 'behavior': 421, 'before': 422, 'automatically': 423, 'automate': 424, 'autoencoders': 425, 'audio': 426, 'attempts': 427, 'architectures': 428, 'architecture': 429, 'approach': 430, 'applicable': 431, 'any': 432, 'ann': 433, 'animal': 434, 'analyzing': 435, 'analyze': 436, 'allow': 437, 'acquisition': 438, '“recurrent': 439, 'yielded': 440, 'writing': 441, 'wreck': 442, 'work': 443, 'wikipedia': 444, 'width': 445, 'widely': 446, 'wide': 447, 'whether': 448, 'whence': 449, 'wellsuited': 450, 'web': 451, 'weather': 452, 'weak': 453, 'ways': 454, 'way': 455, 'wants': 456, 'vs': 457, 'views': 458, 'videos': 459, 'versions': 460, 'vector': 461, 'varying': 462, 'variation': 463, 'variables': 464, 'variable': 465, 'vanishing': 466, 'values': 467, 'vaguely': 468, 'useful': 469, 'usable': 470, 'untagged': 471, 'unsupervisedin': 472, 'unknown': 473, 'universality': 474, 'universal': 475, 'unit': 476, 'unfeasible': 477, 'undirected': 478, 'understandability': 479, 'understand': 480, 'typology': 481, 'types': 482, 'type': 483, 'trimming': 484, 'tries': 485, 'traversing': 486, 'travel': 487, 'transpilers': 488, 'transmit': 489, 'translators': 490, 'translations': 491, 'translate': 492, 'transforms': 493, 'transformations': 494, 'transformation': 495, 'transcribe': 496, 'trainability': 497, 'traffic': 498, 'tracking': 499, 'towards': 500, 'thus': 501, 'three': 502, 'thought': 503, 'those': 504, 'things': 505, 'theories': 506, 'themselves': 507, 'texture': 508, 'textual': 509, 'texttospeech': 510, 'textbooks': 511, 'terms': 512, 'technology': 513, 'technological': 514, 'technique': 515, 'taught': 516, 'target': 517, 'takes': 518, 'tagging': 519, 'symmetrical': 520, 'surpassing': 521, 'supervisory': 522, 'summarization': 523, 'sum': 524, 'successfully': 525, 'substitutions': 526, 'substitution': 527, 'subset': 528, 'subnetworks': 529, 'subnetwork': 530, 'subdomains': 531, 'strong': 532, 'strictly': 533, 'strength': 534, 'stored': 535, 'stimuli': 536, 'step': 537, 'static': 538, 'starting': 539, 'standardised': 540, 'standard': 541, 'stack': 542, 'spectrum': 543, 'specifically': 544, 'special': 545, 'sparsity': 546, 'sparse': 547, 'space': 548, 'sounds': 549, 'sometimes': 550, 'something': 551, 'solution': 552, 'social': 553, 'socalled': 554, 'sl': 555, 'skilled': 556, 'size': 557, 'simply': 558, 'simplify': 559, 'simpler': 560, 'simple': 561, 'similarly': 562, 'significantly': 563, 'signals': 564, 'siann': 565, 'showed': 566, 'should': 567, 'short': 568, 'shivas': 569, 'shift': 570, 'sharedweight': 571, 'share': 572, 'servoing': 573, 'serves': 574, 'sent': 575, 'sensor': 576, 'sense': 577, 'selforganization': 578, 'selfconsistent': 579, 'select': 580, 'segment': 581, 'score': 582, 'scope': 583, 'science': 584, 'scenario': 585, 'scanning': 586, 'scanner': 587, 'scan': 588, 'scale': 589, 'say': 590, 'sample': 591, 'sake': 592, 'review': 593, 'revealed': 594, 'return': 595, 'retrieval': 596, 'retina': 597, 'retaining': 598, 'resulting': 599, 'restoration': 600, 'respond': 601, 'resolve': 602, 'resembles': 603, 'research': 604, 'replacing': 605, 'replaces': 606, 'render': 607, 'remembers': 608, 'relying': 609, 'relationships': 610, 'reinforcement': 611, 'regulate': 612, 'regularized': 613, 'regions': 614, 'refers': 615, 'refer': 616, 'reduced': 617, 'reconstructions': 618, 'reconstruction': 619, 'reconstruct': 620, 'recommender': 621, 'receives': 622, 'reasonable': 623, 'realworld': 624, 'readily': 625, 'read': 626, 'rbms': 627, 'rbm': 628, 'raw': 629, 'rarely': 630, 'rapidlygrowing': 631, 'rapidly': 632, 'randomly': 633, 'quality': 634, 'put': 635, 'psychological': 636, 'psycholinguists': 637, 'provides': 638, 'proved': 639, 'protein': 640, 'proposed': 641, 'property': 642, 'pronunciation': 643, 'prone': 644, 'programs': 645, 'programming': 646, 'programmed': 647, 'program': 648, 'profession': 649, 'production': 650, 'produced': 651, 'processed': 652, 'proceeds': 653, 'procedure': 654, 'problems[2]': 655, 'problems': 656, 'probabilities': 657, 'probabilistically': 658, 'probabilistic': 659, 'prior': 660, 'primitives': 661, 'primarily': 662, 'previous': 663, 'preprocessing': 664, 'prefer': 665, 'predictive': 666, 'predelections': 667, 'potentially': 668, 'potential': 669, 'possibly': 670, 'positional': 671, 'pose': 672, 'portion': 673, 'polynomials': 674, 'points': 675, 'plastic': 676, 'pixel': 677, 'physics': 678, 'physical': 679, 'perspective': 680, 'permitted': 681, 'permits': 682, 'performs': 683, 'performing': 684, 'perceives': 685, 'pavlos': 686, 'partofspeech': 687, 'partitioning': 688, 'particularly': 689, 'partially': 690, 'parsing': 691, 'pairs': 692, 'overlap': 693, 'overfitting': 694, 'organize': 695, 'organizations': 696, 'organization': 697, 'organisms': 698, 'optimized': 699, 'optimize': 700, 'optimization': 701, 'optimal': 702, 'optical': 703, 'opposite': 704, 'older': 705, 'oil': 706, 'observed': 707, 'numerous': 708, 'nuances': 709, 'normalized': 710, 'nonpolynomial': 711, 'no': 712, 'nns': 713, 'nice': 714, 'ngram': 715, 'new': 716, 'neuronal': 717, 'network”': 718, 'need': 719, 'name': 720, 'multivariate': 721, 'multidimensional': 722, 'motivated': 723, 'motion': 724, 'modern': 725, 'modeled': 726, 'mobile': 727, 'mining': 728, 'minimized': 729, 'mind': 730, 'mimicry': 731, 'mimic': 732, 'mild': 733, 'might': 734, 'mechanical': 735, 'measured': 736, 'meaningful': 737, 'meaning': 738, 'maximize': 739, 'matrix': 740, 'mathematically': 741, 'material': 742, 'matched': 743, 'markov': 744, 'marching': 745, 'maps': 746, 'mapping': 747, 'manual': 748, 'manipulation': 749, 'machineaided': 750, 'm': 751, 'loss': 752, 'loosely': 753, 'loops': 754, 'location': 755, 'locate': 756, 'living': 757, 'little': 758, 'linguistic': 759, 'lines': 760, 'linear': 761, 'limiting': 762, 'likelihood': 763, 'levels': 764, 'level': 765, 'less': 766, 'legal': 767, 'led': 768, 'leads': 769, 'layered': 770, 'layerbylayer': 771, 'latter': 772, 'latent': 773, 'last': 774, 'larger': 775, 'lags': 776, 'labels': 777, 'labelled': 778, 'labeling': 779, 'knowledge': 780, 'isolation': 781, 'involves': 782, 'involve': 783, 'investigates': 784, 'invariance': 785, 'intrusion': 786, 'intervention': 787, 'intervals': 788, 'interpolation': 789, 'intermediate': 790, 'interfaces': 791, 'interest': 792, 'interdisciplinary': 793, 'interactions': 794, 'intensity': 795, 'intelligent': 796, 'integrated': 797, 'instances': 798, 'inspection': 799, 'insights': 800, 'insensitivity': 801, 'inputoutput': 802, 'informed': 803, 'infers': 804, 'inferred': 805, 'infeasible': 806, 'inexpensive': 807, 'inductive': 808, 'individual': 809, 'indiscriminately': 810, 'indexing': 811, 'independent': 812, 'independence': 813, 'increasing': 814, 'increases': 815, 'incorporates': 816, 'improving': 817, 'improvement': 818, 'improve': 819, 'important': 820, 'implementation': 821, 'imaging': 822, 'imagery': 823, 'idss': 824, 'idioms': 825, 'idea': 826, 'humanreadable': 827, 'huge': 828, 'hope': 829, 'highlevel': 830, 'highdimensional': 831, 'hierarchical': 832, 'heterogeneous': 833, 'hence': 834, 'help': 835, 'handling': 836, 'handle': 837, 'handengineered': 838, 'hand': 839, 'guidance': 840, 'great': 841, 'graphical': 842, 'gradient': 843, 'gpt': 844, 'government': 845, 'good': 846, 'goals': 847, 'goal': 848, 'go': 849, 'gets': 850, 'geometry': 851, 'generated': 852, 'generalize': 853, 'generalization': 854, 'gates': 855, 'gap': 856, 'game': 857, 'gain': 858, 'further': 859, 'functioning': 860, 'fullyconnectedness': 861, 'frequently': 862, 'formulaic': 863, 'former': 864, 'formal': 865, 'forget': 866, 'forced': 867, 'follows': 868, 'focusing': 869, 'focuses': 870, 'fnn': 871, 'flow': 872, 'fish': 873, 'first': 874, 'finetuned': 875, 'financial': 876, 'fewer': 877, 'fast': 878, 'family': 879, 'falls': 880, 'factorization': 881, 'fact': 882, 'facilitates': 883, 'extreme': 884, 'extracted': 885, 'extra': 886, 'expression': 887, 'express': 888, 'exponentially': 889, 'exploratory': 890, 'explicitly': 891, 'explicit': 892, 'expert': 893, 'experiment': 894, 'experience': 895, 'exhibits': 896, 'examination': 897, 'evidence': 898, 'every': 899, 'events': 900, 'event': 901, 'even': 902, 'estimating': 903, 'especially': 904, 'error': 905, 'erroneous': 906, 'equivalent': 907, 'environment': 908, 'english': 909, 'energybased': 910, 'end': 911, 'encountered': 912, 'encoding': 913, 'encoder': 914, 'enabled': 915, 'enable': 916, 'emulate': 917, 'emotionality': 918, 'embossed': 919, 'email': 920, 'elicit': 921, 'either': 922, 'efficiency': 923, 'effective': 924, 'edge': 925, 'early': 926, 'duration': 927, 'due': 928, 'drug': 929, 'domain': 930, 'does': 931, 'divergence': 932, 'distribution': 933, 'distributed': 934, 'distinguish': 935, 'distinction': 936, 'displayed': 937, 'display': 938, 'disentangling': 939, 'disambiguate': 940, 'direct': 941, 'difficult': 942, 'deviate': 943, 'development': 944, 'developed': 945, 'develop': 946, 'determine': 947, 'detectors': 948, 'desired': 949, 'designed': 950, 'design': 951, 'descriptions': 952, 'described': 953, 'describe': 954, 'derived': 955, 'depends': 956, 'densities': 957, 'demonstrated': 958, 'delivers': 959, 'delays': 960, 'deeplearning': 961, 'decreases': 962, 'decompilers': 963, 'deals': 964, 'dbns': 965, 'cyclic': 966, 'customization': 967, 'curves': 968, 'current': 969, 'cubes': 970, 'crosses': 971, 'create': 972, 'crawl': 973, 'counterparts': 974, 'cost': 975, 'cortical': 976, 'cortex': 977, 'correctly': 978, 'convnet': 979, 'conversations': 980, 'conversation': 981, 'conventional': 982, 'convenient': 983, 'controlled': 984, 'control': 985, 'contrastive': 986, 'contrast': 987, 'contextual': 988, 'contents': 989, 'contained': 990, 'construction': 991, 'constructed': 992, 'constitute': 993, 'consist': 994, 'considered': 995, 'considerations': 996, 'considerably': 997, 'considerable': 998, 'consciousness': 999, 'connectionist': 1000, 'connectedness': 1001, 'conjunction': 1002, 'confused': 1003, 'conditions': 1004, 'concept': 1005, 'computing': 1006, 'computeraided': 1007, 'computationally': 1008, 'compositional': 1009, 'component': 1010, 'comparable': 1011, 'compact': 1012, 'communication': 1013, 'commonly': 1014, 'combines': 1015, 'color': 1016, 'colloquially': 1017, 'collectively': 1018, 'collection': 1019, 'cognitive': 1020, 'code': 1021, 'cnn': 1022, 'clustering': 1023, 'closest': 1024, 'closely': 1025, 'classifying': 1026, 'classifier': 1027, 'chosen': 1028, 'choose': 1029, 'choice': 1030, 'chatbot': 1031, 'characteristic': 1032, 'character': 1033, 'change': 1034, 'chance': 1035, 'challenging': 1036, 'challenges': 1037, 'categorize': 1038, 'categories': 1039, 'cases': 1040, 'car': 1041, 'captures': 1042, 'capable': 1043, 'cannot': 1044, 'cameras': 1045, 'calculate': 1046, 'business': 1047, 'broader': 1048, 'breeds': 1049, 'breed': 1050, 'braincomputer': 1051, 'bounded': 1052, 'boundaries': 1053, 'boltzmann': 1054, 'board': 1055, 'blurbs': 1056, 'biologically': 1057, 'bioinformatics': 1058, 'bidirectional': 1059, 'biases': 1060, 'bias': 1061, 'better': 1062, 'bert': 1063, 'being': 1064, 'behind': 1065, 'beginning': 1066, 'become': 1067, 'because': 1068, 'beach': 1069, 'basic': 1070, 'bag': 1071, 'automated': 1072, 'assumption': 1073, 'associated': 1074, 'associate': 1075, 'assigns': 1076, 'assigning': 1077, 'assemble': 1078, 'arbitrary': 1079, 'approximate': 1080, 'appropriate': 1081, 'apply': 1082, 'anomaly': 1083, 'anomalies': 1084, 'animals': 1085, 'andor': 1086, 'analyzes': 1087, 'analytics': 1088, 'analogue': 1089, 'amounts': 1090, 'american': 1091, 'ambiguous': 1092, 'ambiguity': 1093, 'ambiguities': 1094, 'always': 1095, 'alternatively': 1096, 'alternative': 1097, 'along': 1098, 'alone': 1099, 'allowable': 1100, 'algorithmically': 1101, 'aid': 1102, 'agi': 1103, 'aggregated': 1104, 'aggregate': 1105, 'agents': 1106, 'agent': 1107, 'adjusts': 1108, 'adjective': 1109, 'adjacent': 1110, 'additional': 1111, 'acyclic': 1112, 'activation': 1113, 'actions': 1114, 'action': 1115, 'act': 1116, 'across': 1117, 'acronym': 1118, 'acquiring': 1119, 'acoustic': 1120, 'achieving': 1121, 'accurately': 1122, 'accuracy': 1123, 'above': 1124, 'about': 1125, 'abi': 1126, 'abbreviation': 1127, '2017': 1128, '[mask]': 1129}\n",
            "Mask token Id: 1129\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnBB13KbK6GQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e58bf05-cd0a-4479-f5ef-522066b6b7c8"
      },
      "source": [
        "# Convert input text to tokens\n",
        "all_data_tokens = text_vectorizer(sentences)\n",
        "print(\"Input text:\\n\")\n",
        "print(sentences[0])\n",
        "print(sentences[1])\n",
        "print(sentences[3])\n",
        "print(\"all_data_tokens shape:\",all_data_tokens.shape)\n",
        "print(\"Tokenized text:\", all_data_tokens[:5,:20])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input text:\n",
            "\n",
            "Deep learning also known as deep structured learning is part of a broader family of machine learning methods based on artificial neural networks with representation learning.\n",
            "Learning can be supervised, semi-supervised or unsupervised.\n",
            "Artificial neural networks (ANNs) were inspired by information processing and distributed communication nodes in biological systems.\n",
            "all_data_tokens shape: (183, 66)\n",
            "Tokenized text: tf.Tensor(\n",
            "[[  35    9   37   75   11   35  192    9    7  150    3    4 1048  879\n",
            "     3   23    9  101  109   30]\n",
            " [   9   14   18   55   97   12   83    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0]\n",
            " [ 961  428   20   11   35   16   17   35  420   17   61   16   17    6\n",
            "   244   16   17   44  254  170]\n",
            " [  33   16   17  256  178  220   36   90   57    6  934 1013  206    8\n",
            "    79   60    0    0    0    0]\n",
            " [ 256   44  268  394   25   79  251    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0]], shape=(5, 20), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZODRS8yLNAw"
      },
      "source": [
        "#### **Generate Training Data**\n",
        "\n",
        "For the training we need inputs and lables but we only have input texts. In the lecture we learnt that language models are trained in a semi supervised way where we generate inputs and labels from the input text. \n",
        "\n",
        "<br>\n",
        "\n",
        "To generate inputs and lables for training we will mask random words from the input text. Then our labels will be the masked text. The model will be trained to predict the masked word\n",
        "\n",
        "Steps for generating data:\n",
        "* 15% random tokens are take\n",
        "* 90% of these are masked\n",
        "* the other 10% is set to random tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExB3HRv9LQoh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0543d10a-38b7-445c-fc3a-0dd79287993a"
      },
      "source": [
        "# Since we have a very small dataset, we will just replicate the data\n",
        "encoded_texts = all_data_tokens.numpy()\n",
        "print(encoded_texts.shape)\n",
        "encoded_texts = np.vstack([encoded_texts]*50)\n",
        "print(encoded_texts.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(183, 66)\n",
            "(9150, 66)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fJfUl4PLVYB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17f6fca1-b8a5-4d19-dbe6-112e39f08b0a"
      },
      "source": [
        "# 15% BERT masking\n",
        "inp_mask = np.random.rand(*encoded_texts.shape) < 0.15\n",
        "print(\"inp_mask:\", inp_mask.shape)\n",
        "#print(\"inp_mask:\",inp_mask[0,:25])\n",
        "\n",
        "# Exclude masking special tokens\n",
        "inp_mask[encoded_texts <= 2] = False\n",
        "\n",
        "# Set targets to -1 by default, it means ignore\n",
        "labels = -1 * np.ones(encoded_texts.shape, dtype=int)\n",
        "\n",
        "# Set labels for masked tokens\n",
        "labels[inp_mask] = encoded_texts[inp_mask]\n",
        "\n",
        "# Prepare input\n",
        "encoded_texts_masked = np.copy(encoded_texts)\n",
        "\n",
        "# Set input to [MASK] which is the last token for the 90% of tokens\n",
        "# This means leaving 10% unchanged\n",
        "inp_mask_2mask = inp_mask & (np.random.rand(*encoded_texts.shape) < 0.90)\n",
        "encoded_texts_masked[\n",
        "    inp_mask_2mask\n",
        "] = mask_token_id  # mask token is the last in the dict\n",
        "\n",
        "# Set 10% to a random token\n",
        "inp_mask_2random = inp_mask_2mask & (np.random.rand(*encoded_texts.shape) < 1 / 9)\n",
        "encoded_texts_masked[inp_mask_2random] = np.random.randint(\n",
        "    3, mask_token_id, inp_mask_2random.sum()\n",
        ")\n",
        "\n",
        "# Prepare sample_weights to pass to .fit() method\n",
        "sample_weights = np.ones(labels.shape)\n",
        "sample_weights[labels == -1] = 0\n",
        "\n",
        "# y_labels would be same as encoded_texts i.e input tokens\n",
        "y_labels = np.copy(encoded_texts)\n",
        "\n",
        "print(\"encoded_texts_masked:\",encoded_texts_masked.shape)\n",
        "print(encoded_texts_masked[:5,:10])\n",
        "print(\"y_labels:\",y_labels.shape)\n",
        "print(y_labels[:5,:10])\n",
        "print(\"sample_weights:\",sample_weights.shape)\n",
        "print(sample_weights[:5,:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inp_mask: (9150, 66)\n",
            "encoded_texts_masked: (9150, 66)\n",
            "[[  35    9 1129   75   11   35  192    9    7  150]\n",
            " [   9   14   18   55   97   12   83    0    0    0]\n",
            " [ 961  428   20   11 1129   16   17 1129  420   17]\n",
            " [  33   16 1129 1129 1129  220 1129   90   57    6]\n",
            " [ 256   44  268  394   25   79  251    0    0    0]]\n",
            "y_labels: (9150, 66)\n",
            "[[ 35   9  37  75  11  35 192   9   7 150]\n",
            " [  9  14  18  55  97  12  83   0   0   0]\n",
            " [961 428  20  11  35  16  17  35 420  17]\n",
            " [ 33  16  17 256 178 220  36  90  57   6]\n",
            " [256  44 268 394  25  79 251   0   0   0]]\n",
            "sample_weights: (9150, 66)\n",
            "[[0. 0. 1. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 1. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 1. 1. 1. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSEjg8MOLZUx"
      },
      "source": [
        "#### **Create TF Datasets**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3a3vio8QLbbc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d69d525d-3d2d-4031-ae2b-78970c4ca7b1"
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "TRAIN_SHUFFLE_BUFFER_SIZE = encoded_texts.shape[0]\n",
        "\n",
        "# Create TF Dataset\n",
        "train_data = tf.data.Dataset.from_tensor_slices((encoded_texts_masked, y_labels, sample_weights))\n",
        "\n",
        "#############\n",
        "# Train data\n",
        "#############\n",
        "train_data = train_data.shuffle(buffer_size=TRAIN_SHUFFLE_BUFFER_SIZE)\n",
        "train_data = train_data.batch(BATCH_SIZE)\n",
        "train_data = train_data.prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "print(\"train_data\",train_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_data <PrefetchDataset shapes: ((None, 66), (None, 66), (None, 66)), types: (tf.int64, tf.int64, tf.float64)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrOxBbm5Le2j"
      },
      "source": [
        "### **Build Mini BERT**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ek1IOlpdLkA_"
      },
      "source": [
        "#### **Positional Encoding**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LhIY1oVLjDw"
      },
      "source": [
        "def generate_positional_encoding(max_length, model_size):\n",
        "    pos_enc = np.array(\n",
        "        [\n",
        "            [pos / np.power(10000, 2 * (j // 2) / model_size) for j in range(model_size)]\n",
        "            if pos != 0\n",
        "            else np.zeros(model_size)\n",
        "            for pos in range(max_length)\n",
        "        ]\n",
        "    )\n",
        "    pos_enc[1:, 0::2] = np.sin(pos_enc[1:, 0::2])  # dim 2i\n",
        "    pos_enc[1:, 1::2] = np.cos(pos_enc[1:, 1::2])  # dim 2i+1\n",
        "    return pos_enc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-NdX0arLps-"
      },
      "source": [
        "#### **Transformer Encoder Block**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdFYg1LuLu3r"
      },
      "source": [
        "Here you will build out a Transfomer Encoder block from scratch. You will use this as the building block for the mini BERT model.\n",
        "\n",
        "<img src=\"https://storage.googleapis.com/public_colab_images/nlp/transformer_encoder_block.svg\"/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rB7Wg0wTL7MW"
      },
      "source": [
        "def transfomer_encoder_block(query, key, value, embedding_dim, num_heads, ff_dim):\n",
        "\n",
        "  # 1) Add a keras.layers.MultiHeadAttention Layer\n",
        "  # Set num_heads\n",
        "  # Set key_dim = embedding_dim // num_heads\n",
        "  # Pass in the (query, key, value) to this layer to get the attention_output\n",
        "  attention_output = keras.layers.MultiHeadAttention(num_heads,key_dim=embedding_dim//num_heads)(query,key,value)\n",
        "\n",
        "  # 2) Add Dropout(0.1) to the attention_output\n",
        "  attention_output = keras.layers.Dropout(0.1)(attention_output)\n",
        "\n",
        "  # 3) Normalization + Residual Connection\n",
        "  # Add a keras.layers.LayerNormalization with epsilon=1e-6\n",
        "  # Pass in the query and attention_output to the LayerNormalization\n",
        "  attention_output = keras.layers.LayerNormalization(epsilon=1e-6)(query+attention_output)\n",
        "\n",
        "  # 4) Feedforward Layer\n",
        "  # Add a Dense layer with size ff_dim and activation=\"relu\"\n",
        "  # Pass in attention_output to get the ffn_output\n",
        "  # Add another Dense layer with size of embedding_dim and pass in the ffn_output\n",
        "  ffn_output = keras.layers.Dense(units=ff_dim,activation='relu')(attention_output)\n",
        "  ffn_output = keras.layers.Dense(units=embedding_dim,activation='relu')(ffn_output)\n",
        "\n",
        "  # 5) Add Dropout(0.1) to the ffn_output\n",
        "  ffn_output = keras.layers.Dropout(0.1)(ffn_output)\n",
        "\n",
        "  # 6) Normalization + Residual Connection\n",
        "  # Add a keras.layers.LayerNormalization with epsilon=1e-6\n",
        "  # Pass in the attention_output and ffn_output to the LayerNormalization to get the final sequence_output\n",
        "  sequence_output = keras.layers.LayerNormalization(epsilon=1e-6)(attention_output+ffn_output)\n",
        "\n",
        "\n",
        "  return sequence_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "foRjbyBxMIr-"
      },
      "source": [
        "#### **Masked Language Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_fFZfzTMKw9"
      },
      "source": [
        "# Loss Tracker\n",
        "loss_tracker = tf.keras.metrics.Mean(name=\"loss\")\n",
        "loss_fn = keras.losses.SparseCategoricalCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n",
        "\n",
        "class MaskedLanguageModel(keras.Model):\n",
        "\n",
        "  def train_step(self, inputs):\n",
        "      if len(inputs) == 3:\n",
        "          features, labels, sample_weight = inputs\n",
        "      else:\n",
        "          features, labels = inputs\n",
        "          sample_weight = None\n",
        "\n",
        "      with tf.GradientTape() as tape:\n",
        "          predictions = self(features, training=True)\n",
        "          loss = loss_fn(labels, predictions[0], sample_weight=sample_weight)\n",
        "\n",
        "      # Compute gradients\n",
        "      trainable_vars = self.trainable_variables\n",
        "      gradients = tape.gradient(loss, trainable_vars)\n",
        "\n",
        "      # Update weights\n",
        "      self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "\n",
        "      # Compute our own metrics\n",
        "      loss_tracker.update_state(loss, sample_weight=sample_weight)\n",
        "\n",
        "      # Return a dict mapping metric names to current value\n",
        "      return {\"loss\": loss_tracker.result()}\n",
        "\n",
        "  @property\n",
        "  def metrics(self):\n",
        "      return [loss_tracker]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Np-mVMziMMtB"
      },
      "source": [
        "def create_masked_language_bert_model(vocab_size, embedding_dim, sequence_length,num_layers, num_heads, ff_dim, enable_pe=True):\n",
        "  # Model input\n",
        "  model_input = keras.layers.Input(shape=(sequence_length), dtype=tf.int64)\n",
        "\n",
        "  embeddings = keras.layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim)(model_input)\n",
        "  if enable_pe:\n",
        "    embeddings = embeddings + generate_positional_encoding(sequence_length,embedding_dim)\n",
        "  \n",
        "  encoder_output = embeddings\n",
        "  for i in range(num_layers):\n",
        "      encoder_output = transfomer_encoder_block(encoder_output, encoder_output, encoder_output, embedding_dim,num_heads, ff_dim)\n",
        "\n",
        "  # Output Layer\n",
        "  output = keras.layers.Dense(units=vocab_size, activation=\"softmax\")(encoder_output)\n",
        "\n",
        "  # Create Model\n",
        "  model = MaskedLanguageModel(inputs=[model_input], outputs=[output,encoder_output], name=\"masked_bert_model\")\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBN0YTwTMQEi"
      },
      "source": [
        "### **Train Mini BERT**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LowWbCr5MUTi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cbf3675-fae3-4a89-b455-48604ac61341"
      },
      "source": [
        "############################\n",
        "# Training Params\n",
        "############################\n",
        "epochs = 10\n",
        "learning_rate = 0.001\n",
        "embedding_dim = 256\n",
        "sequence_length = max_len\n",
        "num_layers = 2\n",
        "num_heads = 8\n",
        "ff_dim = 256\n",
        "\n",
        "# Free up memory\n",
        "K.clear_session()\n",
        "\n",
        "# Build the model\n",
        "model_w_pe = create_masked_language_bert_model(vocabulary_size,embedding_dim, sequence_length,num_layers,num_heads,ff_dim, enable_pe=True)\n",
        "\n",
        "# Print the model architecture\n",
        "print(model_w_pe.summary())\n",
        "\n",
        "# Optimizer\n",
        "optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "# Compile\n",
        "model_w_pe.compile(optimizer=optimizer)\n",
        "\n",
        "# Train model\n",
        "start_time = time.time()\n",
        "training_results = model_w_pe.fit(\n",
        "        train_data,\n",
        "        epochs=epochs,\n",
        "        verbose=1)\n",
        "execution_time = (time.time() - start_time)/60.0\n",
        "print(\"Training execution time (mins)\",execution_time)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"masked_bert_model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 66)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 66, 256)      289280      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add (TFOpLambd (None, 66, 256)      0           embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "multi_head_attention (MultiHead (None, 66, 256)      263168      tf.__operators__.add[0][0]       \n",
            "                                                                 tf.__operators__.add[0][0]       \n",
            "                                                                 tf.__operators__.add[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 66, 256)      0           multi_head_attention[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_1 (TFOpLam (None, 66, 256)      0           tf.__operators__.add[0][0]       \n",
            "                                                                 dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization (LayerNorma (None, 66, 256)      512         tf.__operators__.add_1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 66, 256)      65792       layer_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 66, 256)      65792       dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 66, 256)      0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_2 (TFOpLam (None, 66, 256)      0           layer_normalization[0][0]        \n",
            "                                                                 dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_1 (LayerNor (None, 66, 256)      512         tf.__operators__.add_2[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "multi_head_attention_1 (MultiHe (None, 66, 256)      263168      layer_normalization_1[0][0]      \n",
            "                                                                 layer_normalization_1[0][0]      \n",
            "                                                                 layer_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 66, 256)      0           multi_head_attention_1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_3 (TFOpLam (None, 66, 256)      0           layer_normalization_1[0][0]      \n",
            "                                                                 dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_2 (LayerNor (None, 66, 256)      512         tf.__operators__.add_3[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 66, 256)      65792       layer_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 66, 256)      65792       dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 66, 256)      0           dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.add_4 (TFOpLam (None, 66, 256)      0           layer_normalization_2[0][0]      \n",
            "                                                                 dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "layer_normalization_3 (LayerNor (None, 66, 256)      512         tf.__operators__.add_4[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 66, 1130)     290410      layer_normalization_3[0][0]      \n",
            "==================================================================================================\n",
            "Total params: 1,371,242\n",
            "Trainable params: 1,371,242\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Epoch 1/10\n",
            "143/143 [==============================] - 13s 57ms/step - loss: 5.7713\n",
            "Epoch 2/10\n",
            "143/143 [==============================] - 8s 57ms/step - loss: 4.5561\n",
            "Epoch 3/10\n",
            "143/143 [==============================] - 8s 58ms/step - loss: 3.3868\n",
            "Epoch 4/10\n",
            "143/143 [==============================] - 8s 57ms/step - loss: 2.4091\n",
            "Epoch 5/10\n",
            "143/143 [==============================] - 8s 57ms/step - loss: 1.5973\n",
            "Epoch 6/10\n",
            "143/143 [==============================] - 8s 57ms/step - loss: 0.9932\n",
            "Epoch 7/10\n",
            "143/143 [==============================] - 8s 57ms/step - loss: 0.6213\n",
            "Epoch 8/10\n",
            "143/143 [==============================] - 8s 57ms/step - loss: 0.4012\n",
            "Epoch 9/10\n",
            "143/143 [==============================] - 8s 57ms/step - loss: 0.2638\n",
            "Epoch 10/10\n",
            "143/143 [==============================] - 8s 57ms/step - loss: 0.1871\n",
            "Training execution time (mins) 1.8181121826171875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKwigEILMaQI"
      },
      "source": [
        "### **Evaluate**\n",
        "\n",
        "Let us look at what exaclty is the language model predicting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AETv8RhXMc79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7421b00e-339a-41d2-fab1-dcb2573a5231"
      },
      "source": [
        "sample_tokens = text_vectorizer([\"convolutional [mask] networks have been applied to fields including computer vision\"])\n",
        "sample_tokens = sample_tokens.numpy()\n",
        "print(sample_tokens)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 244 1129   17   44  254  170    5  380  370   40   54    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cq5n0jC9MjNa"
      },
      "source": [
        "# Make a prediction\n",
        "predictions = model_w_pe.predict(sample_tokens)\n",
        "\n",
        "# Get the first output from the model\n",
        "mask_predictions = predictions[0]\n",
        "encoder_output = predictions[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAfTvgU1MleU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5442ec5c-5a1a-4802-a447-eff6617836db"
      },
      "source": [
        "masked_index = np.where(sample_tokens == mask_token_id)\n",
        "masked_index = masked_index[1]\n",
        "mask_prediction = mask_predictions[0][masked_index]\n",
        "print(\"mask_prediction:\", mask_prediction)\n",
        "\n",
        "top_indices = mask_prediction[0].argsort()[-5 :][::-1]\n",
        "values = mask_prediction[0][top_indices]\n",
        "\n",
        "def decode(tokens):\n",
        "  return \" \".join([index_word[t] for t in tokens if t != 0])\n",
        "\n",
        "for i in range(len(top_indices)):\n",
        "  p = top_indices[i]\n",
        "  v = values[i]\n",
        "  tokens = np.copy(sample_tokens[0])\n",
        "  tokens[masked_index[0]] = p\n",
        "  print(\"Prediction:\",decode(tokens),\"- Probability:\",v, \"- Mask token:\",index_word[p])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mask_prediction: [[3.6319974e-09 2.8887686e-09 6.9124098e-09 ... 1.9563150e-07\n",
            "  1.1716987e-08 7.8660829e-09]]\n",
            "Prediction: convolutional networks networks have been applied to fields including computer vision - Probability: 0.6575382 - Mask token: networks\n",
            "Prediction: convolutional neural networks have been applied to fields including computer vision - Probability: 0.112526715 - Mask token: neural\n",
            "Prediction: convolutional have networks have been applied to fields including computer vision - Probability: 0.060355756 - Mask token: have\n",
            "Prediction: convolutional of networks have been applied to fields including computer vision - Probability: 0.045830317 - Mask token: of\n",
            "Prediction: convolutional in networks have been applied to fields including computer vision - Probability: 0.033413824 - Mask token: in\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkRFtKw7BkTZ"
      },
      "source": [
        "## **Generate text**\n",
        "---\n",
        "\n",
        "Generate unconditional samples using GPT2. `<|endoftext|>` is the special start token to have the model generate words on its own."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXYYrJoi0lM0"
      },
      "source": [
        "**Load Tokenizer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nI7A4JyI0dvA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "ec098c441ef94be0874b3d7136e99a18",
            "01a4c795851b4a528847b76aad2b398d",
            "32064963fad745769b09c69e8ba2e3fa",
            "cc893a84885b43378c5dcf594432684b",
            "9a4430fd18f94f62b9ab9f23a28da19b",
            "4181692483574dd8b7a941e4be4472ec",
            "8b45ff8ddd084ce6a8cd812c51c9a4d7",
            "86384cf6c29a4fe8ac25a13640b88f80",
            "17eb5d4de97c461c938679ee2a595ee8",
            "40d588b95cd548f998e16170daf28fb2",
            "dadc8529119e47c29d9d1ce32f24ac64",
            "40ee98080fb447eaa66f54929e764527",
            "e05bc5ae30a74d80a39b5b8173879439",
            "ced47c528ecc4e43a179ea2452ad5ff7",
            "3c7833503bf24a0fbff9bbe678d748fe",
            "76f8967e6f2e466fba3f530cb881d284",
            "581c4f61f8b84f8381fcfa516966f240",
            "214c37b88f284ae68e252b9841f67174",
            "a1379a8fe7bc455e8d8582550559ab78",
            "ec96ac160e704d578c2a331b22541958",
            "0d24fb7b873e497ebe04679423f3ab33",
            "bad3ad9993734783b264f01568e20f48",
            "a0e68f9785f242189e21484a8f134587",
            "add07ca7f83a46619ae8f1a7d9f38fad",
            "8956a00f90524f0db2c06d6cfd0bd9ae",
            "85f8b4a240504f6396d6512636bca2e6",
            "3fb9f2185bed4f9793bc14d199264d75",
            "4b9e6167aaf149dbb75eeed119ffa6e8",
            "05a20ce333164f82a3c3898dfc9f9dc0",
            "640b5296ee2b431bbfa3c66148917324",
            "63350e827a934ff4804f37d28cf44c4e",
            "e1c38b9c9df34a769f69f7710e14f201",
            "fe80570419104ca4860057898cb9b3d1",
            "e45ace2bcd2140018e10dd9d2fc171d6",
            "a9191af7e59a4fc4b6623f337bb49c88",
            "bead2ab72817430883a3edc44289ebe2",
            "08e9072d28614afcb0722bf85312f22c",
            "6e4c006ff05f46689ed6cf4848290b96",
            "ab9aaad6f36640649f5b233420a9c47a",
            "cadb2d2d788444c2896e803a6a8fc2e2",
            "2b40b25cf03b496180a6b1fc94a08676",
            "d3bebe08c1a84b798677507d7078cc22",
            "984fb0d7b88b4867930bfced6ae2022b",
            "d3a4ded2a6284341b6e3c4b21ca1d4dc"
          ]
        },
        "outputId": "5023a8a5-1ab1-4c6d-acfc-2a45171efd2a"
      },
      "source": [
        "# Load tokenizer\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ec098c441ef94be0874b3d7136e99a18",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "40ee98080fb447eaa66f54929e764527",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a0e68f9785f242189e21484a8f134587",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e45ace2bcd2140018e10dd9d2fc171d6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2rghHWO0plw"
      },
      "source": [
        "**Load pretrained GPT2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6R44Xh50ebo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142,
          "referenced_widgets": [
            "ce5fdfc2be3449b7aa0daf329814af21",
            "854263b72ba142e19269589573608748",
            "9fc63361eee746ea9121024f18cbc3a7",
            "510493072efd4a548febffcf741ec747",
            "647cb483a33e4394b388b07d52ad17d3",
            "bd44662c9abd4acb8f6293756c496637",
            "ef231a5da93f42b6b7d891e0c268fddc",
            "3ce9227da501480fbb3abdfa0387ca7d",
            "97b3f59779134cd6b28df88a9e787e02",
            "d6205cbfe5d54e4d828977671e7a3661",
            "3e27cf037c3a4123a69a4c79c1bf7575"
          ]
        },
        "outputId": "45abf653-5de9-4119-d996-cea4532564a0"
      },
      "source": [
        "# Model - Load pretrained GPT Language Model\n",
        "model = TFGPT2LMHeadModel.from_pretrained(\"gpt2\", pad_token_id=tokenizer.eos_token_id)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ce5fdfc2be3449b7aa0daf329814af21",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/498M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvXu8bXv0q3w"
      },
      "source": [
        "**Generate Text**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ScxJMxlBuMj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86a674fa-cf1a-4a6c-a19f-9648c46c9812"
      },
      "source": [
        "# Input text\n",
        "input_text = input() # enter a prompt here\n",
        "\n",
        "# Tokenize Input\n",
        "input_ids = tokenizer.encode(input_text, return_tensors='tf')\n",
        "\n",
        "# Generate output\n",
        "outputs = model.generate(\n",
        "    input_ids, \n",
        "    do_sample=True, \n",
        "    max_length=100, \n",
        "    top_p=0.80, \n",
        "    top_k=0\n",
        ")\n",
        "\n",
        "print(\"Generated text:\")\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AI is taking\n",
            "Generated text:\n",
            "AI is taking in $1.2 billion in revenue this year, about 25 percent more than the $5 billion annual sales in 2011. That puts a damper on what can be considered a major free-market business, and contributes to a crisis of confidence in Microsoft as a leader in the world of software, if only its big technology firms were given a platform to compete.\n",
            "\n",
            "Microsoft is a long way from being a voice of reason, if not a voice of reason. For all its\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiyYEbT_B51h"
      },
      "source": [
        "Generate conditional samples using GPT2. Enter a prompt to have GPT2 generate text related to any topic."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0FPoW5HB6V5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4dbecb07-b353-4170-838f-30dc630ab9bb"
      },
      "source": [
        "# Input text\n",
        "input_text = input() # enter a prompt here...\n",
        "\n",
        "# Tokenize Input\n",
        "input_ids = tokenizer.encode(input_text, return_tensors='tf')\n",
        "\n",
        "# Generate output\n",
        "outputs = model.generate(\n",
        "    input_ids, \n",
        "    do_sample=True, \n",
        "    max_length=100, \n",
        "    top_p=0.80, \n",
        "    top_k=0\n",
        ")\n",
        "\n",
        "print(\"Generated text:\")\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Professor\n",
            "Generated text:\n",
            "The Professor is determined to be a multi-award winning professor and an accomplished collegiate runner.\n",
            "\n",
            "The Professor is an accomplished collegiate runner and an accomplished collegiate runner. The Professor's personal growth has been enabled by his incredible inner clarity and personality.\n",
            "\n",
            "The Professor's Personal Growth Has Been Enabled by His Amazing Inner Truths and the Outward Attitude of His Center (Zafar).\n",
            "\n",
            "This project was funded by the Daniel K. Krantz Foundation, which will be holding\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MJtYhic0GAP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}